# Autograd_Word2Vec
A word embedding model is trained using Autograd library.

Word2Vec is a shallow neural network containing 1 input layer, 1 hidden layer and 1 output layer which is used in text processing. It takes raw text as a input and provides set of feature vectors for words present in that raw text. Vectors used to represent a word are called word embedding or word representation. Word2Vec can be applied to find similarity between two given words, grouping similar words together, clustering text documents etc.
